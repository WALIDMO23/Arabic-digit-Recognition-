{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ–¼ï¸ Generic Image Classification Pipeline\n",
    "\n",
    "## Complete Pipeline: From Image Files to Model Deployment\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“š What You Will Learn\n",
    "\n",
    "1. **Image Preprocessing** - Load, resize, convert to grayscale/color\n",
    "2. **Feature Extraction** - Extract HOG, LBP, Color Histogram, and other image features\n",
    "3. **Dataset Preparation** - Organize data into train/test or train/validation/test splits\n",
    "4. **Model Training** - Train and compare multiple ML classifiers\n",
    "5. **Hyperparameter Tuning** - Fine-tune the best model using Grid/Random Search\n",
    "6. **Model Evaluation** - Analyze performance with metrics and visualizations\n",
    "7. **Model Deployment** - Build a Flask web app for browser-based prediction\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ¯ Pipeline Overview\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    IMAGE CLASSIFICATION PIPELINE                             â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                              â”‚\n",
    "â”‚   ğŸ–¼ï¸ Image Files     ğŸ“ Resize/Norm      ğŸ”¬ Features         ğŸ“Š Vectors     â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚\n",
    "â”‚  â”‚ Class 1  â”‚ â”€â”€â”€â”€â–¶ â”‚  Resize  â”‚ â”€â”€â”€â”€â–¶ â”‚   HOG    â”‚ â”€â”€â”€â”€â–¶ â”‚ Feature  â”‚       â”‚\n",
    "â”‚  â”‚ Class 2  â”‚       â”‚ Grayscaleâ”‚       â”‚   LBP    â”‚       â”‚  Vector  â”‚       â”‚\n",
    "â”‚  â”‚ Class N  â”‚       â”‚ Normalizeâ”‚       â”‚  Color   â”‚       â”‚          â”‚       â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜       â”‚\n",
    "â”‚                                                                â”‚             â”‚\n",
    "â”‚                                                                â–¼             â”‚\n",
    "â”‚   ğŸŒ Web Browser     ğŸ† Best Model      ğŸ¤– Train Models   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚  Scale   â”‚       â”‚\n",
    "â”‚  â”‚ Upload & â”‚ â—€â”€â”€â”€â”€ â”‚  Tuned   â”‚ â—€â”€â”€â”€â”€ â”‚ Compare  â”‚ â—€â”€â”€â”€â”€ â”‚   &      â”‚       â”‚\n",
    "â”‚  â”‚ Predict  â”‚       â”‚  Model   â”‚       â”‚ 10 Modelsâ”‚       â”‚  Split   â”‚       â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚\n",
    "â”‚                                                                              â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### âš™ï¸ How to Use This Notebook\n",
    "\n",
    "1. **Customize the Configuration Section** (Step 0) with your class names and file paths\n",
    "2. **Run each cell sequentially** from top to bottom\n",
    "3. **Modify parameters** as needed for your specific use case\n",
    "4. **Save your trained model** for deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“– Ø¯Ù„ÙŠÙ„ Ø§Ù„ØªØ®ØµÙŠØµ Ù„Ù„Ø·Ù„Ø§Ø¨ (Arabic Guide)\n",
    "\n",
    "<div dir=\"rtl\" style=\"text-align: right; background: #f8f9fa; padding: 20px; border-radius: 10px; border-right: 5px solid #667eea;\">\n",
    "\n",
    "### ğŸ¯ ÙƒÙŠÙÙŠØ© ØªØ®ØµÙŠØµ Ù‡Ø°Ø§ Ø§Ù„ÙƒÙˆØ¯ Ù„Ù…Ø´Ø±ÙˆØ¹Ùƒ\n",
    "\n",
    "Ù‡Ø°Ø§ Ø§Ù„Ù€ Notebook Ù…ØµÙ…Ù… Ù„ÙŠÙƒÙˆÙ† **Ù‚Ø§Ø¨Ù„ Ù„Ù„ØªØ®ØµÙŠØµ Ø¨Ø§Ù„ÙƒØ§Ù…Ù„** Ù„Ø£ÙŠ Ù…Ø´Ø±ÙˆØ¹ ØªØµÙ†ÙŠÙ ØµÙˆØ±. Ø§ØªØ¨Ø¹ Ø§Ù„Ø®Ø·ÙˆØ§Øª Ø§Ù„ØªØ§Ù„ÙŠØ©:\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“ Ø§Ù„Ø®Ø·ÙˆØ© 1: ØªØºÙŠÙŠØ± Ø§Ø³Ù… Ø§Ù„Ù…Ø´Ø±ÙˆØ¹\n",
    "\n",
    "```python\n",
    "PROJECT_NAME = \"Ø§Ø³Ù…_Ù…Ø´Ø±ÙˆØ¹Ùƒ\"  # Ù…Ø«Ø§Ù„: \"fashion_mnist\", \"face_emotion\", \"scene_classification\"\n",
    "```\n",
    "\n",
    "**Ø£Ù…Ø«Ù„Ø©:**\n",
    "- ØªØµÙ†ÙŠÙ Ø§Ù„Ø£Ø²ÙŠØ§Ø¡: `\"fashion_classification\"`\n",
    "- ØªØµÙ†ÙŠÙ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±: `\"emotion_recognition\"`\n",
    "- ØªØµÙ†ÙŠÙ Ø§Ù„Ù…Ø´Ø§Ù‡Ø¯: `\"scene_classification\"`\n",
    "- ØªØµÙ†ÙŠÙ Ø§Ù„Ø­ÙŠÙˆØ§Ù†Ø§Øª: `\"animal_classification\"`\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“‚ Ø§Ù„Ø®Ø·ÙˆØ© 2: ØªØ­Ø¯ÙŠØ¯ Ø§Ù„ÙØ¦Ø§Øª ÙˆÙ…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„ØµÙˆØ±\n",
    "\n",
    "#### Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© 1: Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„ØµÙˆØ± ÙÙŠ Ù…Ø¬Ù„Ø¯Ø§Øª Ù…Ù†ÙØµÙ„Ø© Ù„ÙƒÙ„ ÙØ¦Ø©\n",
    "```python\n",
    "DATA_MODE = 'folders'  # Ø§Ù„ØµÙˆØ± Ù…Ù‚Ø³Ù…Ø© ÙÙŠ Ù…Ø¬Ù„Ø¯Ø§Øª\n",
    "DATA_PATH = 'path/to/your/data'\n",
    "# Ù‡ÙŠÙƒÙ„ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª:\n",
    "# data/\n",
    "#   â”œâ”€â”€ class_1/\n",
    "#   â”‚   â”œâ”€â”€ image1.jpg\n",
    "#   â”‚   â””â”€â”€ image2.jpg\n",
    "#   â”œâ”€â”€ class_2/\n",
    "#   â””â”€â”€ class_3/\n",
    "```\n",
    "\n",
    "#### Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© 2: Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„ØµÙˆØ± Ù…Ø¹ Ù…Ù„Ù CSV Ù„Ù„ØªØ³Ù…ÙŠØ§Øª\n",
    "```python\n",
    "DATA_MODE = 'csv'  # Ø§Ù„ØµÙˆØ± Ù…Ø¹ Ù…Ù„Ù CSV\n",
    "IMAGES_PATH = 'path/to/images'\n",
    "LABELS_FILE = 'path/to/labels.csv'\n",
    "IMAGE_COL = 'filename'  # Ø§Ø³Ù… Ø¹Ù…ÙˆØ¯ Ø§Ø³Ù… Ø§Ù„ØµÙˆØ±Ø©\n",
    "LABEL_COL = 'label'     # Ø§Ø³Ù… Ø¹Ù…ÙˆØ¯ Ø§Ù„ØªØ³Ù…ÙŠØ©\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### âš™ï¸ Ø§Ù„Ø®Ø·ÙˆØ© 3: Ø¶Ø¨Ø· Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙˆØ±Ø©\n",
    "\n",
    "| Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯ | Ø§Ù„ÙˆØµÙ | Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙˆØµÙ‰ Ø¨Ù‡Ø§ |\n",
    "|---------|-------|------------------|\n",
    "| `IMG_SIZE` | Ø­Ø¬Ù… Ø§Ù„ØµÙˆØ±Ø© | `(64, 64)` Ù„Ù„Ø³Ø±Ø¹Ø©ØŒ `(128, 128)` Ù„Ù„Ø¯Ù‚Ø© |\n",
    "| `COLOR_MODE` | Ù†ÙˆØ¹ Ø§Ù„Ù„ÙˆÙ† | `'grayscale'` Ù„Ù„Ø£Ø´ÙƒØ§Ù„ØŒ `'rgb'` Ù„Ù„Ø£Ù„ÙˆØ§Ù† |\n",
    "\n",
    "**Ù„Ù„ØµÙˆØ± Ø§Ù„Ø±Ù…Ø§Ø¯ÙŠØ© (Ø§Ù„Ø£Ø´ÙƒØ§Ù„ ÙˆØ§Ù„Ø­ÙˆØ§Ù):**\n",
    "```python\n",
    "IMG_SIZE = (64, 64)\n",
    "COLOR_MODE = 'grayscale'\n",
    "```\n",
    "\n",
    "**Ù„Ù„ØµÙˆØ± Ø§Ù„Ù…Ù„ÙˆÙ†Ø© (Ø§Ù„Ù…Ø´Ø§Ù‡Ø¯ ÙˆØ§Ù„Ø·Ø¨ÙŠØ¹Ø©):**\n",
    "```python\n",
    "IMG_SIZE = (128, 128)\n",
    "COLOR_MODE = 'rgb'\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ¨ Ø§Ù„Ø®Ø·ÙˆØ© 4: Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø®ØµØ§Ø¦Øµ (Features)\n",
    "\n",
    "| Ø§Ù„Ø®Ø§ØµÙŠØ© | Ø§Ù„ÙˆØµÙ | Ù…ØªÙ‰ ØªØ³ØªØ®Ø¯Ù…Ù‡Ø§ØŸ |\n",
    "|---------|-------|---------------|\n",
    "| `USE_HOG` | Ø®ØµØ§Ø¦Øµ Ø§Ù„Ø­ÙˆØ§Ù ÙˆØ§Ù„Ø£Ø´ÙƒØ§Ù„ | âœ… Ù„Ù„Ø£Ø´ÙƒØ§Ù„ ÙˆØ§Ù„ÙˆØ¬ÙˆÙ‡ ÙˆØ§Ù„Ø£Ø²ÙŠØ§Ø¡ |\n",
    "| `USE_LBP` | Ø®ØµØ§Ø¦Øµ Ø§Ù„Ù…Ù„Ù…Ø³ Ø§Ù„Ù…Ø­Ù„ÙŠ | âœ… Ù„Ù„Ù…Ù„Ù…Ø³ ÙˆØ§Ù„ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø¯Ù‚ÙŠÙ‚Ø© |\n",
    "| `USE_COLOR_HIST` | Ù‡ÙŠØ³ØªÙˆØ¬Ø±Ø§Ù… Ø§Ù„Ø£Ù„ÙˆØ§Ù† | âœ… Ù„Ù„ØµÙˆØ± Ø§Ù„Ù…Ù„ÙˆÙ†Ø© ÙˆØ§Ù„Ù…Ø´Ø§Ù‡Ø¯ |\n",
    "| `USE_HSV_HIST` | Ù‡ÙŠØ³ØªÙˆØ¬Ø±Ø§Ù… HSV | âœ… Ù„Ù„ØªÙ…ÙŠÙŠØ² Ø¨ÙŠÙ† Ø§Ù„Ø£Ù„ÙˆØ§Ù† Ø§Ù„Ù…ØªØ´Ø§Ø¨Ù‡Ø© |\n",
    "| `USE_PIXEL` | Ù‚ÙŠÙ… Ø§Ù„Ø¨ÙƒØ³Ù„ Ù…Ø¨Ø§Ø´Ø±Ø© | âš ï¸ ÙÙ‚Ø· Ù„Ù„ØµÙˆØ± Ø§Ù„ØµØºÙŠØ±Ø© Ø¬Ø¯Ø§Ù‹ |\n",
    "\n",
    "**Ù„Ù„Ø£Ø²ÙŠØ§Ø¡ ÙˆØ§Ù„ÙˆØ¬ÙˆÙ‡ (ØµÙˆØ± Ø±Ù…Ø§Ø¯ÙŠØ©):**\n",
    "```python\n",
    "USE_HOG = True\n",
    "USE_LBP = True\n",
    "USE_COLOR_HIST = False\n",
    "USE_HSV_HIST = False\n",
    "```\n",
    "\n",
    "**Ù„Ù„Ù…Ø´Ø§Ù‡Ø¯ ÙˆØ§Ù„Ø·Ø¨ÙŠØ¹Ø© (ØµÙˆØ± Ù…Ù„ÙˆÙ†Ø©):**\n",
    "```python\n",
    "USE_HOG = True\n",
    "USE_LBP = True\n",
    "USE_COLOR_HIST = True\n",
    "USE_HSV_HIST = True\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“Š Ø§Ù„Ø®Ø·ÙˆØ© 5: Ø§Ø®ØªÙŠØ§Ø± Ø·Ø±ÙŠÙ‚Ø© ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n",
    "\n",
    "**Ø§Ù„Ø®ÙŠØ§Ø± 1: ØªØ¯Ø±ÙŠØ¨ ÙˆØ§Ø®ØªØ¨Ø§Ø± ÙÙ‚Ø· (Ù„Ù„ØªØ¬Ø§Ø±Ø¨ Ø§Ù„Ø³Ø±ÙŠØ¹Ø©)**\n",
    "```python\n",
    "USE_VALIDATION_SET = False\n",
    "TRAIN_TEST_RATIO = 0.80  # 80% ØªØ¯Ø±ÙŠØ¨ØŒ 20% Ø§Ø®ØªØ¨Ø§Ø±\n",
    "```\n",
    "\n",
    "**Ø§Ù„Ø®ÙŠØ§Ø± 2: ØªØ¯Ø±ÙŠØ¨ + ØªØ­Ù‚Ù‚ + Ø§Ø®ØªØ¨Ø§Ø± (Ù…ÙˆØµÙ‰ Ø¨Ù‡)**\n",
    "```python\n",
    "USE_VALIDATION_SET = True\n",
    "TRAIN_RATIO = 0.70   # 70% Ù„Ù„ØªØ¯Ø±ÙŠØ¨\n",
    "VAL_RATIO = 0.15     # 15% Ù„Ù„ØªØ­Ù‚Ù‚ (Validation)\n",
    "TEST_RATIO = 0.15    # 15% Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ\n",
    "```\n",
    "\n",
    "**ğŸ’¡ Ù†ØµÙŠØ­Ø©:** Ø§Ø³ØªØ®Ø¯Ù… `USE_VALIDATION_SET = True` Ø¹Ù†Ø¯ Ø§Ø³ØªØ®Ø¯Ø§Ù… Hyperparameter Tuning\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸš€ Ø£Ù…Ø«Ù„Ø© Ù…Ø´Ø§Ø±ÙŠØ¹ ÙƒØ§Ù…Ù„Ø©\n",
    "\n",
    "#### Ù…Ø«Ø§Ù„ 1: ØªØµÙ†ÙŠÙ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ù…Ù† Ø§Ù„ÙˆØ¬ÙˆÙ‡\n",
    "```python\n",
    "PROJECT_NAME = \"emotion_recognition\"\n",
    "DATA_MODE = 'folders'\n",
    "DATA_PATH = 'data/fer2013'\n",
    "IMG_SIZE = (48, 48)\n",
    "COLOR_MODE = 'grayscale'\n",
    "USE_HOG = True\n",
    "USE_LBP = True\n",
    "USE_COLOR_HIST = False\n",
    "```\n",
    "\n",
    "#### Ù…Ø«Ø§Ù„ 2: ØªØµÙ†ÙŠÙ Ø§Ù„Ù…Ø´Ø§Ù‡Ø¯ Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠØ©\n",
    "```python\n",
    "PROJECT_NAME = \"scene_classification\"\n",
    "DATA_MODE = 'folders'\n",
    "DATA_PATH = 'data/intel_scenes'\n",
    "IMG_SIZE = (128, 128)\n",
    "COLOR_MODE = 'rgb'\n",
    "USE_HOG = True\n",
    "USE_LBP = True\n",
    "USE_COLOR_HIST = True\n",
    "USE_HSV_HIST = True\n",
    "```\n",
    "\n",
    "#### Ù…Ø«Ø§Ù„ 3: ØªØµÙ†ÙŠÙ Ø§Ù„Ø£Ø²ÙŠØ§Ø¡ (Fashion-MNIST)\n",
    "```python\n",
    "PROJECT_NAME = \"fashion_mnist\"\n",
    "DATA_MODE = 'csv'\n",
    "IMG_SIZE = (28, 28)\n",
    "COLOR_MODE = 'grayscale'\n",
    "USE_HOG = True\n",
    "USE_LBP = False\n",
    "USE_COLOR_HIST = False\n",
    "```\n",
    "\n",
    "#### Ù…Ø«Ø§Ù„ 4: Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ù…ÙƒØªÙˆØ¨Ø© Ø¨Ø®Ø· Ø§Ù„ÙŠØ¯ (MNIST) âœï¸\n",
    "```python\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© (0-9)\n",
    "# Handwritten Digit Recognition (English)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "PROJECT_NAME = \"handwritten_digit_recognition\"\n",
    "\n",
    "# Ù…ØµØ¯Ø± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª | Data Source\n",
    "DATA_MODE = 'folders'\n",
    "DATA_PATH = 'data/mnist'\n",
    "# Ù‡ÙŠÙƒÙ„ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨:\n",
    "# data/mnist/\n",
    "#   â”œâ”€â”€ 0/\n",
    "#   â”‚   â”œâ”€â”€ img_0001.png\n",
    "#   â”‚   â””â”€â”€ img_0002.png\n",
    "#   â”œâ”€â”€ 1/\n",
    "#   â”œâ”€â”€ 2/\n",
    "#   ....\n",
    "#   â””â”€â”€ 9/\n",
    "\n",
    "# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙˆØ±Ø© | Image Settings\n",
    "IMG_SIZE = (28, 28)        # Ø­Ø¬Ù… MNIST Ø§Ù„Ø£ØµÙ„ÙŠ\n",
    "COLOR_MODE = 'grayscale'   # Ø§Ù„Ø£Ø±Ù‚Ø§Ù… Ø±Ù…Ø§Ø¯ÙŠØ©\n",
    "MAX_IMAGES_PER_CLASS = 1000  # Ù„Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ø³Ø±ÙŠØ¹ (None Ù„ÙƒÙ„ Ø§Ù„ØµÙˆØ±)\n",
    "\n",
    "# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø®ØµØ§Ø¦Øµ | Feature Settings\n",
    "USE_HOG = True             # âœ… Ù…Ù…ØªØ§Ø² Ù„Ù„Ø­ÙˆØ§Ù ÙˆØ§Ù„Ø§Ù†Ø­Ù†Ø§Ø¡Ø§Øª\n",
    "USE_LBP = False            # âŒ ØºÙŠØ± Ø¶Ø±ÙˆØ±ÙŠ Ù„Ù„Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ø¨Ø³ÙŠØ·Ø©\n",
    "USE_COLOR_HIST = False     # âŒ Ø§Ù„ØµÙˆØ± Ø±Ù…Ø§Ø¯ÙŠØ©\n",
    "USE_HSV_HIST = False       # âŒ Ø§Ù„ØµÙˆØ± Ø±Ù…Ø§Ø¯ÙŠØ©\n",
    "USE_PIXEL = False          # âš ï¸ Ø§Ø®ØªÙŠØ§Ø±ÙŠ\n",
    "\n",
    "# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª HOG Ù„Ù„ØµÙˆØ± Ø§Ù„ØµØºÙŠØ±Ø© | HOG Settings for Small Images\n",
    "HOG_ORIENTATIONS = 9\n",
    "HOG_PIXELS_PER_CELL = (4, 4)   # Ø®Ù„Ø§ÙŠØ§ Ø£ØµØºØ± Ù„Ù„ØµÙˆØ± Ø§Ù„ØµØºÙŠØ±Ø©\n",
    "HOG_CELLS_PER_BLOCK = (2, 2)\n",
    "\n",
    "# ğŸ“¦ Ù…ØµØ¯Ø± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: https://www.kaggle.com/datasets/hojjatk/mnist-dataset\n",
    "# ğŸ¯ Ø§Ù„Ø¯Ù‚Ø© Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©: 95-99%\n",
    "# ğŸ† Ø£ÙØ¶Ù„ Ù†Ù…ÙˆØ°Ø¬: SVM (RBF) Ø£Ùˆ Random Forest\n",
    "```\n",
    "\n",
    "#### Ù…Ø«Ø§Ù„ 5: Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ù…ÙƒØªÙˆØ¨Ø© Ø¨Ø®Ø· Ø§Ù„ÙŠØ¯ ğŸ”¢\n",
    "```python\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©/Ø§Ù„Ù‡Ù†Ø¯ÙŠØ© (Ù -Ù©)\n",
    "# Arabic Handwritten Digit Recognition\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "PROJECT_NAME = \"arabic_digit_recognition\"\n",
    "\n",
    "# Ù…ØµØ¯Ø± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª | Data Source\n",
    "DATA_MODE = 'folders'\n",
    "DATA_PATH = 'data/arabic_digits'\n",
    "# Ù‡ÙŠÙƒÙ„ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨:\n",
    "# data/arabic_digits/\n",
    "#   â”œâ”€â”€ 0/    (Ù )\n",
    "#   â”œâ”€â”€ 1/    (Ù¡)\n",
    "#   â”œâ”€â”€ 2/    (Ù¢)\n",
    "#   â”œâ”€â”€ 3/    (Ù£)\n",
    "#   â”œâ”€â”€ 4/    (Ù¤)\n",
    "#   â”œâ”€â”€ 5/    (Ù¥)\n",
    "#   â”œâ”€â”€ 6/    (Ù¦)\n",
    "#   â”œâ”€â”€ 7/    (Ù§)\n",
    "#   â”œâ”€â”€ 8/    (Ù¨)\n",
    "#   â””â”€â”€ 9/    (Ù©)\n",
    "\n",
    "# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙˆØ±Ø© | Image Settings\n",
    "IMG_SIZE = (32, 32)        # Ø­Ø¬Ù… Ù…Ù†Ø§Ø³Ø¨ Ù„Ù„Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©\n",
    "COLOR_MODE = 'grayscale'\n",
    "MAX_IMAGES_PER_CLASS = None  # Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙƒÙ„ Ø§Ù„ØµÙˆØ±\n",
    "\n",
    "# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø®ØµØ§Ø¦Øµ | Feature Settings\n",
    "USE_HOG = True             # âœ… Ù…Ù…ØªØ§Ø² Ù„Ù„Ø­ÙˆØ§Ù\n",
    "USE_LBP = True             # âœ… Ù…ÙÙŠØ¯ Ù„Ù„ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø¯Ù‚ÙŠÙ‚Ø© ÙÙŠ Ø§Ù„Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©\n",
    "USE_COLOR_HIST = False\n",
    "USE_HSV_HIST = False\n",
    "USE_PIXEL = False\n",
    "\n",
    "# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª HOG | HOG Settings\n",
    "HOG_ORIENTATIONS = 9\n",
    "HOG_PIXELS_PER_CELL = (4, 4)\n",
    "HOG_CELLS_PER_BLOCK = (2, 2)\n",
    "\n",
    "# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª LBP | LBP Settings\n",
    "LBP_RADIUS = 2\n",
    "LBP_POINTS = 16\n",
    "\n",
    "# ğŸ“¦ Ù…ØµØ¯Ø± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: https://www.kaggle.com/datasets/mloey1/ahdd1\n",
    "# ğŸ¯ Ø§Ù„Ø¯Ù‚Ø© Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©: 94-98%\n",
    "# ğŸ† Ø£ÙØ¶Ù„ Ù†Ù…ÙˆØ°Ø¬: SVM (RBF) Ø£Ùˆ Random Forest\n",
    "```\n",
    "\n",
    "#### ğŸ’¡ Ù†ØµØ§Ø¦Ø­ Ø®Ø§ØµØ© Ø¨Ø§Ù„Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ù…ÙƒØªÙˆØ¨Ø© Ø¨Ø®Ø· Ø§Ù„ÙŠØ¯\n",
    "\n",
    "| Ø§Ù„Ù†ØµÙŠØ­Ø© | Ø§Ù„ØªÙØ§ØµÙŠÙ„ |\n",
    "|---------|----------|\n",
    "| **HOG Ù‡Ùˆ Ø§Ù„Ø£ÙØ¶Ù„** | ÙŠÙ„ØªÙ‚Ø· Ø§Ù„Ø­ÙˆØ§Ù ÙˆØ§Ù„Ø§Ù†Ø­Ù†Ø§Ø¡Ø§Øª Ø§Ù„Ù…Ù…ÙŠØ²Ø© Ù„ÙƒÙ„ Ø±Ù‚Ù… |\n",
    "| **Ø®Ù„Ø§ÙŠØ§ ØµØºÙŠØ±Ø©** | Ø§Ø³ØªØ®Ø¯Ù… `(4,4)` Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† `(8,8)` Ù„Ù„ØµÙˆØ± Ø§Ù„ØµØºÙŠØ±Ø© |\n",
    "| **LBP Ù„Ù„Ø¹Ø±Ø¨ÙŠØ©** | Ù…ÙÙŠØ¯ Ù„Ù„Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ù„Ø£Ù†Ù‡Ø§ ØªØ­ØªÙˆÙŠ ØªÙØ§ØµÙŠÙ„ Ø£ÙƒØ«Ø± |\n",
    "| **SVM Ø£Ùˆ RF** | Ù‡Ø°Ø§Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬Ø§Ù† ÙŠØ¹Ø·ÙŠØ§Ù† Ø£ÙØ¶Ù„ Ù†ØªØ§Ø¦Ø¬ |\n",
    "| **Augmentation** | Ø¯ÙˆØ±Ø§Ù† Ø¨Ø³ÙŠØ· (Â±10Â°) ÙŠØ­Ø³Ù† Ø§Ù„Ø¯Ù‚Ø© |\n",
    "\n",
    "---\n",
    "\n",
    "### âš ï¸ Ø£Ø®Ø·Ø§Ø¡ Ø´Ø§Ø¦Ø¹Ø© ÙŠØ¬Ø¨ ØªØ¬Ù†Ø¨Ù‡Ø§\n",
    "\n",
    "| Ø§Ù„Ø®Ø·Ø£ | Ø§Ù„Ø­Ù„ |\n",
    "|-------|------|\n",
    "| Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ù„Ù ØºÙŠØ± ØµØ­ÙŠØ­ | ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… `os.path.exists()` |\n",
    "| Ø¹Ø¯Ø¯ Ø§Ù„ØµÙˆØ± Ù‚Ù„ÙŠÙ„ Ø¬Ø¯Ø§Ù‹ | Ø¬Ù…Ù‘Ø¹ Ø§Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø£Ùˆ Ø§Ø³ØªØ®Ø¯Ù… Data Augmentation |\n",
    "| Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ overfitting | Ø§Ø³ØªØ®Ø¯Ù… `USE_VALIDATION_SET = True` |\n",
    "| Ø§Ù„Ø¯Ù‚Ø© Ù…Ù†Ø®ÙØ¶Ø© | Ø¬Ø±Ø¨ Ø®ØµØ§Ø¦Øµ Ù…Ø®ØªÙ„ÙØ© Ø£Ùˆ Ø²ÙŠØ§Ø¯Ø© Ø­Ø¬Ù… Ø§Ù„ØµÙˆØ±Ø© |\n",
    "| Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¨Ø·ÙŠØ¡ | Ù‚Ù„Ù„ Ø­Ø¬Ù… Ø§Ù„ØµÙˆØ±Ø© Ø£Ùˆ Ø¹Ø¯Ø¯ Ø§Ù„ØµÙˆØ± |\n",
    "| Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø£Ù„ÙˆØ§Ù† | ØªØ£ÙƒØ¯ Ù…Ù† `COLOR_MODE` Ù…Ù†Ø§Ø³Ø¨ Ù„Ù„ØµÙˆØ± |\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ’¡ Ù„Ù„Ù…Ø³Ø§Ø¹Ø¯Ø©\n",
    "\n",
    "Ø¥Ø°Ø§ ÙˆØ§Ø¬Ù‡Øª Ø£ÙŠ Ù…Ø´ÙƒÙ„Ø©:\n",
    "1. ØªØ£ÙƒØ¯ Ù…Ù† ØªØ«Ø¨ÙŠØª Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©\n",
    "2. ØªØ­Ù‚Ù‚ Ù…Ù† Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„ØµÙˆØ±\n",
    "3. Ø±Ø§Ø¬Ø¹ Ø±Ø³Ø§Ø¦Ù„ Ø§Ù„Ø®Ø·Ø£ Ø¨Ø¹Ù†Ø§ÙŠØ©\n",
    "4. Ø¬Ø±Ø¨ Ù…Ø¹ Ø¹Ø¯Ø¯ ØµÙˆØ± Ø£Ù‚Ù„ Ø£ÙˆÙ„Ø§Ù‹ Ù„Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø¹Ù…Ù„ Ø§Ù„ÙƒÙˆØ¯\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“¦ Step 0: Configuration & Setup\n",
    "\n",
    "### âš ï¸ CUSTOMIZE THIS SECTION FOR YOUR PROJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# â•‘                         ğŸ”§ PROJECT CONFIGURATION                           â•‘\n",
    "# â•‘                                                                            â•‘\n",
    "# â•‘  âš ï¸  MODIFY THIS SECTION FOR YOUR SPECIFIC PROJECT  âš ï¸                    â•‘\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# PROJECT NAME (used for output directories and saved models)\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "PROJECT_NAME = \"my_image_classification\"  # e.g., \"emotion_recognition\", \"scene_classification\"\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# DATA SOURCE CONFIGURATION\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "DATA_MODE = 'folders'  # Options: 'folders' or 'csv'\n",
    "\n",
    "# If DATA_MODE = 'folders':\n",
    "# Your data should be organized as:\n",
    "#   data_path/\n",
    "#     â”œâ”€â”€ class_1/\n",
    "#     â”‚   â”œâ”€â”€ img1.jpg\n",
    "#     â”‚   â””â”€â”€ img2.jpg\n",
    "#     â”œâ”€â”€ class_2/\n",
    "#     â””â”€â”€ class_3/\n",
    "DATA_PATH = 'data/my_dataset'  # Path to your organized data\n",
    "\n",
    "# If DATA_MODE = 'csv':\n",
    "IMAGES_PATH = 'data/images'    # Path to images folder\n",
    "LABELS_FILE = 'data/labels.csv'  # Path to CSV with labels\n",
    "IMAGE_COL = 'filename'         # Column name for image filename\n",
    "LABEL_COL = 'label'            # Column name for class label\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# IMAGE PROCESSING SETTINGS\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "IMG_SIZE = (64, 64)            # (width, height) - Resize all images to this size\n",
    "                               # Smaller = faster, Larger = more detail\n",
    "                               # Common sizes: (28,28), (64,64), (128,128), (224,224)\n",
    "\n",
    "COLOR_MODE = 'grayscale'       # Options: 'grayscale' or 'rgb'\n",
    "                               # 'grayscale' for shapes/edges (fashion, digits, faces)\n",
    "                               # 'rgb' for color-dependent tasks (scenes, objects)\n",
    "\n",
    "MAX_IMAGES_PER_CLASS = None    # Set to a number to limit images per class, None for all\n",
    "                               # Useful for balancing classes or quick testing\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# FEATURE EXTRACTION SETTINGS\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "USE_HOG = True                 # Histogram of Oriented Gradients (edges/shapes)\n",
    "USE_LBP = True                 # Local Binary Patterns (texture)\n",
    "USE_COLOR_HIST = False         # RGB Color Histogram (requires COLOR_MODE='rgb')\n",
    "USE_HSV_HIST = False           # HSV Color Histogram (requires COLOR_MODE='rgb')\n",
    "USE_PIXEL = False              # Raw pixel values (only for very small images)\n",
    "\n",
    "# HOG Parameters\n",
    "HOG_ORIENTATIONS = 9           # Number of gradient orientations\n",
    "HOG_PIXELS_PER_CELL = (8, 8)   # Cell size in pixels\n",
    "HOG_CELLS_PER_BLOCK = (2, 2)   # Cells per block for normalization\n",
    "\n",
    "# LBP Parameters\n",
    "LBP_RADIUS = 3                 # Radius for LBP\n",
    "LBP_POINTS = 24                # Number of points for LBP (typically 8 * radius)\n",
    "\n",
    "# Color Histogram Parameters\n",
    "COLOR_HIST_BINS = 32           # Number of bins per channel\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# DATASET SPLIT CONFIGURATION\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "USE_VALIDATION_SET = True      # Set to False for train/test only\n",
    "                               # Set to True for train/validation/test split\n",
    "\n",
    "# If USE_VALIDATION_SET = True:\n",
    "TRAIN_RATIO = 0.70             # 70% for training\n",
    "VAL_RATIO = 0.15               # 15% for validation\n",
    "TEST_RATIO = 0.15              # 15% for testing\n",
    "\n",
    "# If USE_VALIDATION_SET = False:\n",
    "TRAIN_TEST_RATIO = 0.80        # 80% train, 20% test\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# OUTPUT DIRECTORIES\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "OUTPUT_DIR = f'{PROJECT_NAME}_dataset'    # Dataset output directory\n",
    "MODELS_DIR = f'{PROJECT_NAME}_models'     # Saved models directory\n",
    "RESULTS_DIR = f'{PROJECT_NAME}_results'   # Results and visualizations\n",
    "\n",
    "# Random seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "print(\"âœ… Configuration loaded!\")\n",
    "print(f\"   Project: {PROJECT_NAME}\")\n",
    "print(f\"   Data Mode: {DATA_MODE}\")\n",
    "print(f\"   Image Size: {IMG_SIZE}\")\n",
    "print(f\"   Color Mode: {COLOR_MODE}\")\n",
    "print(f\"   Features: HOG={USE_HOG}, LBP={USE_LBP}, ColorHist={USE_COLOR_HIST}, HSV={USE_HSV_HIST}\")\n",
    "print(f\"   Split Mode: {'Train/Validation/Test' if USE_VALIDATION_SET else 'Train/Test only'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# â•‘                         ğŸ“¦ INSTALL DEPENDENCIES                            â•‘\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# Uncomment and run this cell if you need to install dependencies\n",
    "!pip install numpy pandas scikit-learn scikit-image opencv-python matplotlib seaborn joblib flask tqdm pillow -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# â•‘                         ğŸ“š IMPORT LIBRARIES                                â•‘\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "import time\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "from shutil import copy2\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Image processing\n",
    "from skimage.feature import hog, local_binary_pattern\n",
    "from skimage import exposure\n",
    "\n",
    "# Scikit-learn imports\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    classification_report, \n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score\n",
    ")\n",
    "\n",
    "# ML Models\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    AdaBoostClassifier,\n",
    "    ExtraTreesClassifier\n",
    ")\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "print(\"âœ… All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# â•‘                         ğŸ“ CREATE OUTPUT DIRECTORIES                       â•‘\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "for directory in [OUTPUT_DIR, MODELS_DIR, RESULTS_DIR]:\n",
    "    Path(directory).mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"ğŸ“ Created: {directory}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ–¼ï¸ Step 1: Load and Preprocess Images\n",
    "\n",
    "### This step loads images from your data source and prepares them for feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# â•‘                         ğŸ–¼ï¸ IMAGE LOADING FUNCTIONS                         â•‘\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def load_image(image_path: str, img_size: Tuple[int, int], color_mode: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Load and preprocess a single image.\n",
    "    \n",
    "    Args:\n",
    "        image_path: Path to the image file\n",
    "        img_size: Target size (width, height)\n",
    "        color_mode: 'grayscale' or 'rgb'\n",
    "    \n",
    "    Returns:\n",
    "        Preprocessed image as numpy array\n",
    "    \"\"\"\n",
    "    # Read image\n",
    "    if color_mode == 'grayscale':\n",
    "        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    else:\n",
    "        img = cv2.imread(image_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    if img is None:\n",
    "        raise ValueError(f\"Could not load image: {image_path}\")\n",
    "    \n",
    "    # Resize\n",
    "    img = cv2.resize(img, img_size)\n",
    "    \n",
    "    return img\n",
    "\n",
    "\n",
    "def load_images_from_folders(data_path: str, img_size: Tuple[int, int], \n",
    "                             color_mode: str, max_per_class: Optional[int] = None) -> Tuple[np.ndarray, np.ndarray, List[str]]:\n",
    "    \"\"\"\n",
    "    Load images organized in class folders.\n",
    "    \n",
    "    Args:\n",
    "        data_path: Path to root folder containing class subfolders\n",
    "        img_size: Target image size\n",
    "        color_mode: 'grayscale' or 'rgb'\n",
    "        max_per_class: Maximum images per class (None for all)\n",
    "    \n",
    "    Returns:\n",
    "        images: Array of images\n",
    "        labels: Array of label indices\n",
    "        class_names: List of class names\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "    class_names = sorted([d for d in os.listdir(data_path) \n",
    "                         if os.path.isdir(os.path.join(data_path, d))])\n",
    "    \n",
    "    print(f\"\\nğŸ“‚ Loading images from: {data_path}\")\n",
    "    print(f\"ğŸ“‹ Found {len(class_names)} classes: {class_names}\")\n",
    "    \n",
    "    for class_idx, class_name in enumerate(class_names):\n",
    "        class_path = os.path.join(data_path, class_name)\n",
    "        image_files = glob(os.path.join(class_path, '*.jpg')) + \\\n",
    "                     glob(os.path.join(class_path, '*.png')) + \\\n",
    "                     glob(os.path.join(class_path, '*.jpeg'))\n",
    "        \n",
    "        if max_per_class:\n",
    "            image_files = image_files[:max_per_class]\n",
    "        \n",
    "        print(f\"   ğŸ–¼ï¸ {class_name}: {len(image_files)} images\")\n",
    "        \n",
    "        for img_path in image_files:\n",
    "            try:\n",
    "                img = load_image(img_path, img_size, color_mode)\n",
    "                images.append(img)\n",
    "                labels.append(class_idx)\n",
    "            except Exception as e:\n",
    "                continue\n",
    "    \n",
    "    return np.array(images), np.array(labels), class_names\n",
    "\n",
    "\n",
    "def load_images_from_csv(images_path: str, labels_file: str, image_col: str, label_col: str,\n",
    "                        img_size: Tuple[int, int], color_mode: str, \n",
    "                        max_per_class: Optional[int] = None) -> Tuple[np.ndarray, np.ndarray, List[str]]:\n",
    "    \"\"\"\n",
    "    Load images with labels from CSV file.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(labels_file)\n",
    "    class_names = sorted(df[label_col].unique().tolist())\n",
    "    \n",
    "    # Create label encoder\n",
    "    le = LabelEncoder()\n",
    "    le.fit(class_names)\n",
    "    \n",
    "    print(f\"\\nğŸ“‚ Loading images from CSV: {labels_file}\")\n",
    "    print(f\"ğŸ“‹ Found {len(class_names)} classes: {class_names}\")\n",
    "    \n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    # Limit per class if specified\n",
    "    if max_per_class:\n",
    "        df = df.groupby(label_col).head(max_per_class)\n",
    "    \n",
    "    for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Loading images\"):\n",
    "        img_path = os.path.join(images_path, str(row[image_col]))\n",
    "        try:\n",
    "            img = load_image(img_path, img_size, color_mode)\n",
    "            images.append(img)\n",
    "            labels.append(le.transform([row[label_col]])[0])\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    return np.array(images), np.array(labels), class_names\n",
    "\n",
    "print(\"âœ… Image loading functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# â•‘                         ğŸ“¥ LOAD YOUR IMAGES                                â•‘\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“¥ Loading Images\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if DATA_MODE == 'folders':\n",
    "    images, labels, CLASS_NAMES = load_images_from_folders(\n",
    "        DATA_PATH, IMG_SIZE, COLOR_MODE, MAX_IMAGES_PER_CLASS\n",
    "    )\n",
    "elif DATA_MODE == 'csv':\n",
    "    images, labels, CLASS_NAMES = load_images_from_csv(\n",
    "        IMAGES_PATH, LABELS_FILE, IMAGE_COL, LABEL_COL,\n",
    "        IMG_SIZE, COLOR_MODE, MAX_IMAGES_PER_CLASS\n",
    "    )\n",
    "else:\n",
    "    raise ValueError(f\"Unknown DATA_MODE: {DATA_MODE}\")\n",
    "\n",
    "print(f\"\\nâœ… Loaded {len(images)} images!\")\n",
    "print(f\"   ğŸ“Š Images shape: {images.shape}\")\n",
    "print(f\"   ğŸ“Š Labels shape: {labels.shape}\")\n",
    "print(f\"   ğŸ“Š Classes: {CLASS_NAMES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# â•‘                         ğŸ“Š VISUALIZE SAMPLE IMAGES                         â•‘\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ–¼ï¸ Sample Images\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "n_classes = len(CLASS_NAMES)\n",
    "n_cols = min(5, n_classes)\n",
    "n_rows = (n_classes + n_cols - 1) // n_cols\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(3*n_cols, 3*n_rows))\n",
    "if n_rows == 1:\n",
    "    axes = [axes]\n",
    "axes = np.array(axes).flatten()\n",
    "\n",
    "for i, class_name in enumerate(CLASS_NAMES):\n",
    "    idx = np.where(labels == i)[0]\n",
    "    if len(idx) > 0:\n",
    "        sample_idx = idx[0]\n",
    "        if COLOR_MODE == 'grayscale':\n",
    "            axes[i].imshow(images[sample_idx], cmap='gray')\n",
    "        else:\n",
    "            axes[i].imshow(images[sample_idx])\n",
    "        axes[i].set_title(f'{class_name}\\n({len(idx)} imgs)')\n",
    "        axes[i].axis('off')\n",
    "\n",
    "# Hide empty subplots\n",
    "for i in range(len(CLASS_NAMES), len(axes)):\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle(f'ğŸ–¼ï¸ Sample from Each Class ({PROJECT_NAME})', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{RESULTS_DIR}/sample_images.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# â•‘                         ğŸ“Š CLASS DISTRIBUTION                              â•‘\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "unique, counts = np.unique(labels, return_counts=True)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "colors = plt.cm.viridis(np.linspace(0, 0.8, len(CLASS_NAMES)))\n",
    "bars = plt.bar(CLASS_NAMES, counts, color=colors)\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "plt.title(f'ğŸ“Š Class Distribution ({PROJECT_NAME})')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, count in zip(bars, counts):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5, \n",
    "             str(count), ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{RESULTS_DIR}/class_distribution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Check for imbalance\n",
    "imbalance_ratio = max(counts) / min(counts)\n",
    "if imbalance_ratio > 2:\n",
    "    print(f\"âš ï¸ Warning: Class imbalance detected (ratio: {imbalance_ratio:.1f}x)\")\n",
    "    print(\"   Consider using stratified sampling or class weights.\")\n",
    "else:\n",
    "    print(f\"âœ… Classes are relatively balanced (ratio: {imbalance_ratio:.1f}x)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ”¬ Step 2: Feature Extraction\n",
    "\n",
    "### Extract discriminative features from images using HOG, LBP, and Color Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# â•‘                         ğŸ”¬ FEATURE EXTRACTION FUNCTIONS                    â•‘\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def extract_hog_features(image: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Extract HOG (Histogram of Oriented Gradients) features.\n",
    "    Good for capturing shapes and edges.\n",
    "    \"\"\"\n",
    "    # Convert to grayscale if needed\n",
    "    if len(image.shape) == 3:\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    else:\n",
    "        gray = image\n",
    "    \n",
    "    features = hog(\n",
    "        gray,\n",
    "        orientations=HOG_ORIENTATIONS,\n",
    "        pixels_per_cell=HOG_PIXELS_PER_CELL,\n",
    "        cells_per_block=HOG_CELLS_PER_BLOCK,\n",
    "        channel_axis=None\n",
    "    )\n",
    "    return features\n",
    "\n",
    "\n",
    "def extract_lbp_features(image: np.ndarray, n_bins: int = 26) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Extract LBP (Local Binary Pattern) features.\n",
    "    Good for capturing texture patterns.\n",
    "    \"\"\"\n",
    "    # Convert to grayscale if needed\n",
    "    if len(image.shape) == 3:\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    else:\n",
    "        gray = image\n",
    "    \n",
    "    lbp = local_binary_pattern(gray, LBP_POINTS, LBP_RADIUS, method='uniform')\n",
    "    hist, _ = np.histogram(lbp.ravel(), bins=n_bins, range=(0, n_bins))\n",
    "    hist = hist.astype('float32')\n",
    "    hist /= (hist.sum() + 1e-6)  # Normalize\n",
    "    return hist\n",
    "\n",
    "\n",
    "def extract_color_histogram(image: np.ndarray, n_bins: int = 32) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Extract RGB color histogram features.\n",
    "    Good for color-based discrimination.\n",
    "    \"\"\"\n",
    "    if len(image.shape) != 3:\n",
    "        return np.array([])  # Skip for grayscale\n",
    "    \n",
    "    features = []\n",
    "    for i in range(3):  # RGB channels\n",
    "        hist, _ = np.histogram(image[:,:,i].ravel(), bins=n_bins, range=(0, 256))\n",
    "        hist = hist.astype('float32')\n",
    "        hist /= (hist.sum() + 1e-6)  # Normalize\n",
    "        features.extend(hist)\n",
    "    return np.array(features)\n",
    "\n",
    "\n",
    "def extract_hsv_histogram(image: np.ndarray, n_bins: int = 32) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Extract HSV color histogram features.\n",
    "    Good for color-based tasks with lighting variations.\n",
    "    \"\"\"\n",
    "    if len(image.shape) != 3:\n",
    "        return np.array([])  # Skip for grayscale\n",
    "    \n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "    features = []\n",
    "    for i in range(3):  # HSV channels\n",
    "        hist, _ = np.histogram(hsv[:,:,i].ravel(), bins=n_bins, range=(0, 256))\n",
    "        hist = hist.astype('float32')\n",
    "        hist /= (hist.sum() + 1e-6)  # Normalize\n",
    "        features.extend(hist)\n",
    "    return np.array(features)\n",
    "\n",
    "\n",
    "def extract_pixel_features(image: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Extract raw pixel values as features.\n",
    "    Only recommended for very small images.\n",
    "    \"\"\"\n",
    "    return image.flatten().astype('float32') / 255.0\n",
    "\n",
    "\n",
    "def extract_all_features(image: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Extract all enabled features from an image.\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    \n",
    "    if USE_HOG:\n",
    "        features.extend(extract_hog_features(image))\n",
    "    \n",
    "    if USE_LBP:\n",
    "        features.extend(extract_lbp_features(image))\n",
    "    \n",
    "    if USE_COLOR_HIST and len(image.shape) == 3:\n",
    "        features.extend(extract_color_histogram(image, COLOR_HIST_BINS))\n",
    "    \n",
    "    if USE_HSV_HIST and len(image.shape) == 3:\n",
    "        features.extend(extract_hsv_histogram(image, COLOR_HIST_BINS))\n",
    "    \n",
    "    if USE_PIXEL:\n",
    "        features.extend(extract_pixel_features(image))\n",
    "    \n",
    "    return np.array(features)\n",
    "\n",
    "print(\"âœ… Feature extraction functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# â•‘                         ğŸ”¬ EXTRACT FEATURES FROM ALL IMAGES                â•‘\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ”¬ Extracting Features\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Show which features are enabled\n",
    "print(f\"\\nğŸ“‹ Enabled Features:\")\n",
    "print(f\"   HOG: {USE_HOG}\")\n",
    "print(f\"   LBP: {USE_LBP}\")\n",
    "print(f\"   Color Histogram: {USE_COLOR_HIST}\")\n",
    "print(f\"   HSV Histogram: {USE_HSV_HIST}\")\n",
    "print(f\"   Raw Pixels: {USE_PIXEL}\")\n",
    "\n",
    "# Extract features\n",
    "all_features = []\n",
    "\n",
    "for img in tqdm(images, desc=\"Extracting features\"):\n",
    "    features = extract_all_features(img)\n",
    "    all_features.append(features)\n",
    "\n",
    "X = np.array(all_features)\n",
    "y = labels\n",
    "\n",
    "print(f\"\\nâœ… Feature extraction complete!\")\n",
    "print(f\"   ğŸ“Š Feature matrix shape: {X.shape}\")\n",
    "print(f\"   ğŸ“Š Features per image: {X.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# â•‘                         ğŸ¨ VISUALIZE HOG FEATURES                          â•‘\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "if USE_HOG:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ğŸ¨ HOG Visualization\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Select a sample image\n",
    "    sample_idx = np.random.randint(0, len(images))\n",
    "    sample_img = images[sample_idx]\n",
    "    \n",
    "    # Convert to grayscale if needed\n",
    "    if len(sample_img.shape) == 3:\n",
    "        gray = cv2.cvtColor(sample_img, cv2.COLOR_RGB2GRAY)\n",
    "    else:\n",
    "        gray = sample_img\n",
    "    \n",
    "    # Get HOG with visualization\n",
    "    hog_features, hog_image = hog(\n",
    "        gray,\n",
    "        orientations=HOG_ORIENTATIONS,\n",
    "        pixels_per_cell=HOG_PIXELS_PER_CELL,\n",
    "        cells_per_block=HOG_CELLS_PER_BLOCK,\n",
    "        visualize=True,\n",
    "        channel_axis=None\n",
    "    )\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    \n",
    "    axes[0].imshow(gray, cmap='gray')\n",
    "    axes[0].set_title(f'Original Image\\n{CLASS_NAMES[labels[sample_idx]]}')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    axes[1].imshow(hog_image, cmap='gray')\n",
    "    axes[1].set_title('HOG Visualization')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    plt.suptitle('ğŸ”¬ HOG Feature Visualization', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{RESULTS_DIR}/hog_visualization.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## âœ‚ï¸ Step 3: Split Dataset\n",
    "\n",
    "### Split data into train/validation/test sets with stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# â•‘                         âœ‚ï¸ SPLIT DATASET                                   â•‘\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ‚ï¸ Splitting Dataset\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if USE_VALIDATION_SET:\n",
    "    # First split: train vs (val + test)\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "        X, y, \n",
    "        test_size=(VAL_RATIO + TEST_RATIO),\n",
    "        stratify=y,\n",
    "        random_state=RANDOM_SEED\n",
    "    )\n",
    "    \n",
    "    # Second split: val vs test\n",
    "    val_test_ratio = TEST_RATIO / (VAL_RATIO + TEST_RATIO)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(\n",
    "        X_temp, y_temp,\n",
    "        test_size=val_test_ratio,\n",
    "        stratify=y_temp,\n",
    "        random_state=RANDOM_SEED\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Split: Train/Validation/Test\")\n",
    "    print(f\"   Training set: {X_train.shape[0]} samples ({TRAIN_RATIO*100:.0f}%)\")\n",
    "    print(f\"   Validation set: {X_val.shape[0]} samples ({VAL_RATIO*100:.0f}%)\")\n",
    "    print(f\"   Test set: {X_test.shape[0]} samples ({TEST_RATIO*100:.0f}%)\")\n",
    "    \n",
    "else:\n",
    "    # Simple train/test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y,\n",
    "        test_size=(1 - TRAIN_TEST_RATIO),\n",
    "        stratify=y,\n",
    "        random_state=RANDOM_SEED\n",
    "    )\n",
    "    X_val, y_val = None, None\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Split: Train/Test only\")\n",
    "    print(f\"   Training set: {X_train.shape[0]} samples ({TRAIN_TEST_RATIO*100:.0f}%)\")\n",
    "    print(f\"   Test set: {X_test.shape[0]} samples ({(1-TRAIN_TEST_RATIO)*100:.0f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# â•‘                         ğŸ“ SCALE FEATURES                                  â•‘\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“ Scaling Features\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create and fit scaler on training data only!\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transform other sets\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "if USE_VALIDATION_SET:\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "print(\"\\nâœ… Features scaled!\")\n",
    "print(f\"   ğŸ“Š Training mean: {X_train_scaled.mean():.6f} (should be ~0)\")\n",
    "print(f\"   ğŸ“Š Training std: {X_train_scaled.std():.6f} (should be ~1)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ¤– Step 4: Train and Compare Models\n",
    "\n",
    "### Train multiple ML classifiers and compare their performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# â•‘                         ğŸ¤– DEFINE MODELS                                   â•‘\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=RANDOM_SEED),\n",
    "    'SVM (Linear)': SVC(kernel='linear', probability=True, random_state=RANDOM_SEED),\n",
    "    'SVM (RBF)': SVC(kernel='rbf', probability=True, random_state=RANDOM_SEED),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=RANDOM_SEED, n_jobs=-1),\n",
    "    'Extra Trees': ExtraTreesClassifier(n_estimators=100, random_state=RANDOM_SEED, n_jobs=-1),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=RANDOM_SEED),\n",
    "    'AdaBoost': AdaBoostClassifier(n_estimators=100, random_state=RANDOM_SEED),\n",
    "    'KNN (k=5)': KNeighborsClassifier(n_neighbors=5, n_jobs=-1),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=RANDOM_SEED)\n",
    "}\n",
    "\n",
    "print(f\"ğŸ“‹ Defined {len(models)} models for comparison\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# â•‘                         ğŸ‹ï¸ TRAIN AND COMPARE MODELS                        â•‘\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ‹ï¸ Training Models\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "results = []\n",
    "\n",
    "# Choose evaluation set\n",
    "if USE_VALIDATION_SET:\n",
    "    X_eval, y_eval = X_val_scaled, y_val\n",
    "    eval_name = \"Validation\"\n",
    "else:\n",
    "    X_eval, y_eval = X_test_scaled, y_test\n",
    "    eval_name = \"Test\"\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nâ³ Training: {name}...\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    train_time = time.time() - start_time\n",
    "    \n",
    "    # Evaluate\n",
    "    y_pred = model.predict(X_eval)\n",
    "    \n",
    "    acc = accuracy_score(y_eval, y_pred)\n",
    "    f1 = f1_score(y_eval, y_pred, average='weighted')\n",
    "    prec = precision_score(y_eval, y_pred, average='weighted')\n",
    "    rec = recall_score(y_eval, y_pred, average='weighted')\n",
    "    \n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': acc,\n",
    "        'F1-Score': f1,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'Train Time (s)': train_time\n",
    "    })\n",
    "    \n",
    "    print(f\"   âœ… Accuracy: {acc:.4f}, F1: {f1:.4f}, Time: {train_time:.2f}s\")\n",
    "\n",
    "# Create results DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values('Accuracy', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"ğŸ“Š Results Summary ({eval_name} Set)\")\n",
    "print(\"=\"*60)\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Save results\n",
    "results_df.to_csv(f'{RESULTS_DIR}/model_comparison.csv', index=False)\n",
    "\n",
    "# Get best model\n",
    "best_name = results_df.iloc[0]['Model']\n",
    "best_accuracy = results_df.iloc[0]['Accuracy']\n",
    "print(f\"\\nğŸ† Best Model: {best_name} ({best_accuracy*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# â•‘                         ğŸ“Š VISUALIZE MODEL COMPARISON                      â•‘\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Accuracy comparison\n",
    "colors = plt.cm.viridis(np.linspace(0, 0.8, len(results_df)))\n",
    "axes[0].barh(results_df['Model'], results_df['Accuracy'], color=colors)\n",
    "axes[0].set_xlabel('Accuracy')\n",
    "axes[0].set_title('ğŸ¯ Accuracy Comparison')\n",
    "axes[0].set_xlim([0, 1])\n",
    "for i, v in enumerate(results_df['Accuracy']):\n",
    "    axes[0].text(v + 0.01, i, f'{v:.3f}', va='center')\n",
    "\n",
    "# Training time comparison\n",
    "axes[1].barh(results_df['Model'], results_df['Train Time (s)'], color=colors)\n",
    "axes[1].set_xlabel('Time (seconds)')\n",
    "axes[1].set_title('â±ï¸ Training Time')\n",
    "\n",
    "plt.suptitle(f'ğŸ“Š Model Comparison ({PROJECT_NAME})', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{RESULTS_DIR}/model_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ”§ Step 5: Hyperparameter Tuning\n",
    "\n",
    "### Fine-tune the best model using Grid Search or Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# â•‘                         ğŸ”§ HYPERPARAMETER TUNING CONFIG                    â•‘\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "TUNING_METHOD = 'grid'  # Options: 'grid' or 'random'\n",
    "CV_FOLDS = 5           # Number of cross-validation folds\n",
    "MODEL_TO_TUNE = best_name  # Model to tune (from comparison results)\n",
    "\n",
    "# Hyperparameter grids for different models\n",
    "param_grids = {\n",
    "    'SVM (RBF)': {\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'gamma': ['scale', 'auto', 0.01, 0.1],\n",
    "    },\n",
    "    'SVM (Linear)': {\n",
    "        'C': [0.01, 0.1, 1, 10, 100],\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "    },\n",
    "    'KNN (k=5)': {\n",
    "        'n_neighbors': [3, 5, 7, 9, 11],\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'metric': ['euclidean', 'manhattan'],\n",
    "    },\n",
    "    'Logistic Regression': {\n",
    "        'C': [0.01, 0.1, 1, 10, 100],\n",
    "        'solver': ['lbfgs', 'liblinear'],\n",
    "    },\n",
    "    'Gradient Boosting': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'max_depth': [3, 5, 7],\n",
    "    },\n",
    "}\n",
    "\n",
    "print(f\"ğŸ“‹ Tuning: {MODEL_TO_TUNE}\")\n",
    "print(f\"   Method: {TUNING_METHOD} search\")\n",
    "print(f\"   CV Folds: {CV_FOLDS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# â•‘                         ğŸ”§ RUN HYPERPARAMETER TUNING                       â•‘\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"ğŸ”§ Hyperparameter Tuning: {MODEL_TO_TUNE}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if MODEL_TO_TUNE in param_grids:\n",
    "    base_model = models[MODEL_TO_TUNE]\n",
    "    param_grid = param_grids[MODEL_TO_TUNE]\n",
    "    \n",
    "    print(f\"\\nğŸ“‹ Parameter grid: {param_grid}\")\n",
    "    \n",
    "    # Create search object\n",
    "    if TUNING_METHOD == 'grid':\n",
    "        search = GridSearchCV(\n",
    "            base_model, param_grid, \n",
    "            cv=CV_FOLDS, scoring='accuracy', \n",
    "            n_jobs=-1, verbose=1\n",
    "        )\n",
    "    else:\n",
    "        search = RandomizedSearchCV(\n",
    "            base_model, param_grid,\n",
    "            n_iter=20, cv=CV_FOLDS,\n",
    "            scoring='accuracy', n_jobs=-1,\n",
    "            random_state=RANDOM_SEED, verbose=1\n",
    "        )\n",
    "    \n",
    "    # Run search\n",
    "    print(\"\\nâ³ Running search (this may take a while)...\")\n",
    "    start_time = time.time()\n",
    "    search.fit(X_train_scaled, y_train)\n",
    "    tuning_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\nâœ… Tuning complete in {tuning_time:.1f} seconds!\")\n",
    "    print(f\"\\nğŸ† Best parameters: {search.best_params_}\")\n",
    "    print(f\"ğŸ† Best CV score: {search.best_score_:.4f}\")\n",
    "    \n",
    "    # Use the best model\n",
    "    best_model = search.best_estimator_\n",
    "    \n",
    "else:\n",
    "    print(f\"\\nâš ï¸ No parameter grid defined for {MODEL_TO_TUNE}\")\n",
    "    print(\"   Using the original model without tuning.\")\n",
    "    best_model = models[MODEL_TO_TUNE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“Š Step 6: Final Evaluation on Test Set\n",
    "\n",
    "### Evaluate the tuned model on the held-out test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# â•‘                         ğŸ“Š FINAL EVALUATION                                â•‘\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“Š Final Evaluation on Test Set\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate metrics\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "test_f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f\"\\nğŸ† Test Set Results:\")\n",
    "print(f\"   Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "print(f\"   F1-Score: {test_f1:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“‹ Classification Report\")\n",
    "print(\"=\"*60)\n",
    "print(classification_report(y_test, y_pred, target_names=CLASS_NAMES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# â•‘                         ğŸ”¢ CONFUSION MATRIX                                â•‘\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=CLASS_NAMES, yticklabels=CLASS_NAMES)\n",
    "plt.title(f'ğŸ”¢ Confusion Matrix - {MODEL_TO_TUNE}\\nAccuracy: {test_accuracy:.2%}')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{RESULTS_DIR}/confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ’¾ Step 7: Save Model\n",
    "\n",
    "### Save the trained model and preprocessing objects for deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# â•‘                         ğŸ’¾ SAVE MODEL AND ARTIFACTS                        â•‘\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ’¾ Saving Model\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "models_path = Path(MODELS_DIR)\n",
    "\n",
    "# Save the best model\n",
    "joblib.dump(best_model, models_path / 'best_model.pkl')\n",
    "\n",
    "# Save the scaler\n",
    "joblib.dump(scaler, models_path / 'scaler.pkl')\n",
    "\n",
    "# Save label encoder (class names)\n",
    "le = LabelEncoder()\n",
    "le.fit(CLASS_NAMES)\n",
    "joblib.dump(le, models_path / 'label_encoder.pkl')\n",
    "\n",
    "# Save model info\n",
    "model_info = {\n",
    "    'project_name': PROJECT_NAME,\n",
    "    'model_name': MODEL_TO_TUNE,\n",
    "    'test_accuracy': test_accuracy,\n",
    "    'class_names': CLASS_NAMES,\n",
    "    'img_size': IMG_SIZE,\n",
    "    'color_mode': COLOR_MODE,\n",
    "    'feature_config': {\n",
    "        'use_hog': USE_HOG,\n",
    "        'use_lbp': USE_LBP,\n",
    "        'use_color_hist': USE_COLOR_HIST,\n",
    "        'use_hsv_hist': USE_HSV_HIST,\n",
    "        'use_pixel': USE_PIXEL,\n",
    "        'hog_orientations': HOG_ORIENTATIONS,\n",
    "        'hog_pixels_per_cell': HOG_PIXELS_PER_CELL,\n",
    "        'hog_cells_per_block': HOG_CELLS_PER_BLOCK,\n",
    "        'lbp_radius': LBP_RADIUS,\n",
    "        'lbp_points': LBP_POINTS,\n",
    "        'color_hist_bins': COLOR_HIST_BINS,\n",
    "    }\n",
    "}\n",
    "joblib.dump(model_info, models_path / 'model_info.pkl')\n",
    "\n",
    "print(f\"\\nâœ… Saved to {MODELS_DIR}/:\")\n",
    "print(f\"   - best_model.pkl\")\n",
    "print(f\"   - scaler.pkl\")\n",
    "print(f\"   - label_encoder.pkl\")\n",
    "print(f\"   - model_info.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸŒ Step 8: Flask Web App\n",
    "\n",
    "### Generate a Flask web application for browser-based prediction\n",
    "\n",
    "**Features:**\n",
    "- **Drag & drop** image upload\n",
    "- **Real-time prediction** in browser\n",
    "- **Visual probability bars**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# â•‘                      ğŸŒ GENERATE FLASK WEB APP                             â•‘\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "flask_code = f'''\"\"\"Image Classification Web App - {PROJECT_NAME}\"\"\"\n",
    "from flask import Flask, request, jsonify, render_template_string\n",
    "import numpy as np\n",
    "import cv2\n",
    "import joblib\n",
    "import tempfile\n",
    "import os\n",
    "from skimage.feature import hog, local_binary_pattern\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load model and artifacts\n",
    "model = joblib.load(\"{MODELS_DIR}/best_model.pkl\")\n",
    "scaler = joblib.load(\"{MODELS_DIR}/scaler.pkl\")\n",
    "label_encoder = joblib.load(\"{MODELS_DIR}/label_encoder.pkl\")\n",
    "info = joblib.load(\"{MODELS_DIR}/model_info.pkl\")\n",
    "\n",
    "# Config from saved info\n",
    "IMG_SIZE = tuple(info[\"img_size\"])\n",
    "COLOR_MODE = info[\"color_mode\"]\n",
    "fc = info.get(\"feature_config\", {{}})\n",
    "\n",
    "print(f\"Loaded! Classes: {{list(label_encoder.classes_)}}\")\n",
    "\n",
    "def extract_features(image):\n",
    "    \"\"\"Extract features from image using saved config.\"\"\"\n",
    "    features = []\n",
    "    \n",
    "    # Convert to grayscale for HOG/LBP\n",
    "    if len(image.shape) == 3:\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    else:\n",
    "        gray = image\n",
    "    \n",
    "    # HOG\n",
    "    if fc.get(\"use_hog\", True):\n",
    "        hog_feat = hog(\n",
    "            gray,\n",
    "            orientations=fc.get(\"hog_orientations\", 9),\n",
    "            pixels_per_cell=tuple(fc.get(\"hog_pixels_per_cell\", (8, 8))),\n",
    "            cells_per_block=tuple(fc.get(\"hog_cells_per_block\", (2, 2))),\n",
    "            channel_axis=None\n",
    "        )\n",
    "        features.extend(hog_feat)\n",
    "    \n",
    "    # LBP\n",
    "    if fc.get(\"use_lbp\", True):\n",
    "        lbp = local_binary_pattern(gray, fc.get(\"lbp_points\", 24), fc.get(\"lbp_radius\", 3), method=\"uniform\")\n",
    "        hist, _ = np.histogram(lbp.ravel(), bins=26, range=(0, 26))\n",
    "        hist = hist.astype(\"float32\")\n",
    "        hist /= (hist.sum() + 1e-6)\n",
    "        features.extend(hist)\n",
    "    \n",
    "    # Color histogram\n",
    "    if fc.get(\"use_color_hist\", False) and len(image.shape) == 3:\n",
    "        bins = fc.get(\"color_hist_bins\", 32)\n",
    "        for i in range(3):\n",
    "            hist, _ = np.histogram(image[:,:,i].ravel(), bins=bins, range=(0, 256))\n",
    "            hist = hist.astype(\"float32\") / (hist.sum() + 1e-6)\n",
    "            features.extend(hist)\n",
    "    \n",
    "    # HSV histogram\n",
    "    if fc.get(\"use_hsv_hist\", False) and len(image.shape) == 3:\n",
    "        hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "        bins = fc.get(\"color_hist_bins\", 32)\n",
    "        for i in range(3):\n",
    "            hist, _ = np.histogram(hsv[:,:,i].ravel(), bins=bins, range=(0, 256))\n",
    "            hist = hist.astype(\"float32\") / (hist.sum() + 1e-6)\n",
    "            features.extend(hist)\n",
    "    \n",
    "    # Raw pixels\n",
    "    if fc.get(\"use_pixel\", False):\n",
    "        features.extend(image.flatten().astype(\"float32\") / 255.0)\n",
    "    \n",
    "    return np.array(features)\n",
    "\n",
    "HTML = \\'\\'\\'<!DOCTYPE html><html><head><meta charset=\"UTF-8\"><meta name=\"viewport\" content=\"width=device-width,initial-scale=1\"><title>{PROJECT_NAME}</title>\n",
    "<style>*{{margin:0;padding:0;box-sizing:border-box}}body{{font-family:system-ui;background:linear-gradient(135deg,#667eea,#764ba2);min-height:100vh;padding:20px;display:flex;justify-content:center;align-items:center}}\n",
    ".card{{background:#fff;border-radius:20px;padding:40px;max-width:600px;width:100%;box-shadow:0 20px 60px rgba(0,0,0,.3)}}h1{{text-align:center;margin-bottom:30px;color:#333}}\n",
    ".drop{{border:3px dashed #667eea;border-radius:15px;padding:40px;text-align:center;cursor:pointer;transition:.3s}}.drop:hover,.drop.over{{background:#f0f4ff;border-color:#764ba2}}\n",
    ".preview{{max-width:200px;max-height:200px;margin:10px auto;display:none;border-radius:10px}}\n",
    ".btn{{background:linear-gradient(135deg,#667eea,#764ba2);color:#fff;border:none;padding:15px 40px;font-size:16px;border-radius:30px;cursor:pointer;margin-top:20px}}.btn:disabled{{opacity:.5}}\n",
    ".result{{margin-top:30px;padding:20px;background:#f8f9fa;border-radius:15px;display:none}}.result.show{{display:block}}.pred{{font-size:24px;font-weight:bold;color:#667eea;text-align:center}}\n",
    ".bar{{margin:8px 0}}.bar-label{{display:flex;justify-content:space-between;font-size:14px}}.bar-track{{background:#e9ecef;border-radius:8px;height:20px;overflow:hidden}}\n",
    ".bar-fill{{height:100%;border-radius:8px;transition:width .5s}}.load{{display:none;text-align:center;margin:20px}}.spin{{border:4px solid #f3f3f3;border-top:4px solid #667eea;border-radius:50%;width:30px;height:30px;animation:spin 1s linear infinite;margin:0 auto}}@keyframes spin{{to{{transform:rotate(360deg)}}}}\n",
    "</style></head><body><div class=\"card\"><h1>ğŸ–¼ï¸ {PROJECT_NAME}</h1>\n",
    "<div class=\"drop\" id=\"drop\"><p style=\"font-size:40px\">ğŸ“</p><p><b>Drag & drop</b> image here or click to browse</p><p id=\"fname\" style=\"color:#667eea;margin-top:10px\"></p><img class=\"preview\" id=\"preview\"></div>\n",
    "<input type=\"file\" id=\"file\" accept=\"image/*\" hidden><center><button class=\"btn\" id=\"btn\" disabled onclick=\"predict()\">ğŸ”® Predict</button></center>\n",
    "<div class=\"load\" id=\"load\"><div class=\"spin\"></div><p>Analyzing...</p></div>\n",
    "<div class=\"result\" id=\"result\"><div class=\"pred\" id=\"pred\"></div><p style=\"text-align:center;color:#666;margin:10px\" id=\"conf\"></p><div id=\"probs\"></div></div>\n",
    "</div><script>\n",
    "let file=null;const drop=document.getElementById(\"drop\"),inp=document.getElementById(\"file\"),btn=document.getElementById(\"btn\"),preview=document.getElementById(\"preview\");\n",
    "drop.onclick=()=>inp.click();drop.ondragover=e=>{{e.preventDefault();drop.classList.add(\"over\")}};\n",
    "drop.ondragleave=()=>drop.classList.remove(\"over\");drop.ondrop=e=>{{e.preventDefault();drop.classList.remove(\"over\");if(e.dataTransfer.files[0])setFile(e.dataTransfer.files[0])}};\n",
    "inp.onchange=e=>{{if(e.target.files[0])setFile(e.target.files[0])}};\n",
    "function setFile(f){{file=f;document.getElementById(\"fname\").textContent=f.name;btn.disabled=false;document.getElementById(\"result\").classList.remove(\"show\");\n",
    "const reader=new FileReader();reader.onload=e=>{{preview.src=e.target.result;preview.style.display=\"block\"}};reader.readAsDataURL(f)}}\n",
    "async function predict(){{if(!file)return;const fd=new FormData();fd.append(\"image\",file);document.getElementById(\"load\").style.display=\"block\";document.getElementById(\"result\").classList.remove(\"show\");btn.disabled=true;\n",
    "try{{const r=await fetch(\"/predict\",{{method:\"POST\",body:fd}});const d=await r.json();if(d.error)alert(d.error);else show(d)}}catch(e){{alert(e)}}\n",
    "document.getElementById(\"load\").style.display=\"none\";btn.disabled=false}}\n",
    "function show(d){{document.getElementById(\"pred\").textContent=\"ğŸ¯ \"+d.predicted_class;document.getElementById(\"conf\").textContent=\"Confidence: \"+d.confidence.toFixed(1)+\"%\";\n",
    "const p=document.getElementById(\"probs\");p.innerHTML=\"\";const colors=[\"#667eea\",\"#764ba2\",\"#f093fb\",\"#43e97b\",\"#f5576c\",\"#4facfe\",\"#00f2fe\",\"#fa709a\",\"#fee140\",\"#30cfd0\"];\n",
    "Object.entries(d.all_probabilities).sort((a,b)=>b[1]-a[1]).forEach(([c,v],i)=>{{p.innerHTML+=`<div class=\"bar\"><div class=\"bar-label\"><span>${{c}}</span><span>${{v.toFixed(1)}}%</span></div><div class=\"bar-track\"><div class=\"bar-fill\" style=\"width:${{v}}%;background:${{colors[i%colors.length]}}\"></div></div></div>`}});\n",
    "document.getElementById(\"result\").classList.add(\"show\")}}\n",
    "</script></body></html>\\'\\'\\'\\'\n",
    "\n",
    "@app.route(\"/\")\n",
    "def home():\n",
    "    return render_template_string(HTML)\n",
    "\n",
    "@app.route(\"/predict\", methods=[\"POST\"])\n",
    "def predict():\n",
    "    if \"image\" not in request.files:\n",
    "        return jsonify({{\"error\": \"No image uploaded\"}}), 400\n",
    "    \n",
    "    # Save uploaded file temporarily\n",
    "    with tempfile.NamedTemporaryFile(delete=False, suffix=\".jpg\") as tmp:\n",
    "        request.files[\"image\"].save(tmp.name)\n",
    "        path = tmp.name\n",
    "    \n",
    "    try:\n",
    "        # Load and preprocess image\n",
    "        if COLOR_MODE == \"grayscale\":\n",
    "            img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        else:\n",
    "            img = cv2.imread(path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        img = cv2.resize(img, IMG_SIZE)\n",
    "        \n",
    "        # Extract features\n",
    "        features = extract_features(img)\n",
    "        features_scaled = scaler.transform([features])\n",
    "        \n",
    "        # Predict\n",
    "        pred = model.predict(features_scaled)[0]\n",
    "        cls = label_encoder.inverse_transform([pred])[0]\n",
    "        \n",
    "        # Get probabilities\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            probs = model.predict_proba(features_scaled)[0]\n",
    "            prob_dict = {{c: float(probs[i])*100 for i, c in enumerate(label_encoder.classes_)}}\n",
    "        else:\n",
    "            prob_dict = {{c: 100.0 if c == cls else 0.0 for c in label_encoder.classes_}}\n",
    "        \n",
    "        return jsonify({{\n",
    "            \"predicted_class\": cls,\n",
    "            \"confidence\": max(prob_dict.values()),\n",
    "            \"all_probabilities\": prob_dict\n",
    "        }})\n",
    "    \n",
    "    except Exception as e:\n",
    "        return jsonify({{\"error\": str(e)}}), 500\n",
    "    \n",
    "    finally:\n",
    "        os.unlink(path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\\\n\" + \"=\"*50)\n",
    "    print(f\"{PROJECT_NAME} Web App\")\n",
    "    print(\"=\"*50)\n",
    "    print(\"ğŸŒ Open: http://localhost:5000\")\n",
    "    print(\"=\"*50)\n",
    "    app.run(debug=True, port=5000)\n",
    "'''\n",
    "\n",
    "with open('app.py', 'w') as f:\n",
    "    f.write(flask_code)\n",
    "\n",
    "print(\"âœ… Flask app saved as 'app.py'\")\n",
    "print(\"\\n\" + \"-\"*50)\n",
    "print(\"To run: python app.py\")\n",
    "print(\"Open:   http://localhost:5000\")\n",
    "print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“‹ Summary\n",
    "\n",
    "| Step | Description |\n",
    "|------|-------------|\n",
    "| 0 | Configuration â†’ Set project name, data paths, image settings |\n",
    "| 1 | Image Loading â†’ Load and preprocess images |\n",
    "| 2 | Feature Extraction â†’ Extract HOG, LBP, Color features |\n",
    "| 3 | Dataset Split â†’ Train/Validation/Test split with scaling |\n",
    "| 4 | Model Training â†’ Compare 10 ML models |\n",
    "| 5 | Hyperparameter Tuning â†’ Grid/Random Search |\n",
    "| 6 | Final Evaluation â†’ Test set metrics and confusion matrix |\n",
    "| 7 | Save Model â†’ Export for deployment |\n",
    "| 8 | Web Deployment â†’ Flask app with browser UI |\n",
    "\n",
    "---\n",
    "\n",
    "**Pattern Recognition Course - Faculty of Computers and Information - Mansoura University**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
